\chapter{Analysis}
We will describe some of the aspects of handling student submissions
in this analysis chapter of the report

\section{Data overview}

The system are required to handle  several sensitive data items which must be
protected from adversaries before the online assessment system can be
put into production. The types of data are listed here in order of
decreasing sensitivity.

\begin{enumerate}
  \item The submissions of other students
  \item The code for assessing an assignment
  \item The completed assessments of assignments.
\end{enumerate}

The first two items on the list are close in terms of
sensitivity. We regard the submissions of other students as being the
most sensitive data since they have a larger potential to enable
plagiarism.

Since it would have less impact if an adversary gained unintended access
to the code for assessing an assignment we don't assign it the same
sensitivity. Getting access to the assessment code would only tell you
what kind of output that your assignment should produce in order to
pass. It would not tell you how to implement the actual assignment. Thus,
an assignment that is "`tuned"' to produce the output or contain the
phrases that is checked for would not pass subsequent human
inspection. A possible exception to this occurs should this system
ever be used to correct assignments with a single correct answer. In
this case, getting hold of the assessment code equates acquiring the
answers for the assignment

% However, we don't expect the system to be
%commonly used in this way.

Assessments generated by the system is the least sensitive data being
handled since the, a) do not identify students by name and b) they
won't directly give information about how to solve an assignment.

Because of the data that we handle, securing assignments from
unauthorized access is our primary priority.

\section{Personas}
We will here consider two different types of persons interacting with
the system.

\subsection{Student}
A student is the actor submitting assignments to the system. As a rule
of thumb, we assume that we cannot trust code submitted by students.

\subsection{Teacher}
A teacher has the role of creating and uploading new assignments. A
teacher is allowed much more unrestricted access to the system. As a
consequence of this, the teacher is partly responsible 

\section{Assignment types}
Assignment submissions can take various forms

\begin{itemize}
\item a byte stream, e.g. a submission entered into a form on a website
\item a single file, e.g. a self-contained program
\item An archive containing several files and folders
\end{itemize}.

For each of these submissions, we want to,

\begin{itemize}
\item Validate their structure
\item Check for cheating or possible malicious behavior
\item Execute the submitted code
\item Perform a sanity check that the environment they run in is left
  in a valid state.
\end{itemize}

%Types of assignment. Some assignments are complete folders, some
%assingments are just simple files. Some students may prefer to work in
%a straight forward web browser instead of uploading files


%    Validate the structure of the submission.
%    Check that they are not cheating or trying to game the system.
%    Interpret some part of their submission as code and run it.
%    Check that the environment they leave behind after running is valid (e.g. produce a valid file-system in a file-systems assignment in OSM).
%\end{verbatim}



\section{Assessment flow}
A submission goes through several phases of assessment categorized as
either static or dynamic assessment.

The static testing phase assess a submission without ever executing
any submitted code.

The dynamic testing phase will actually execute student submitted and
compare its responses against a set of included reference answers.

The reason for this separation is that we can let two different security
models govern the two phases. The static testing phase requires direct
access to the submitted code, however, since the code is not executed,
we minimize the risk of leakage of any of the scripts for performing
the static assessment. In the dynamic phase, it is necessary to
execute submitted code. Therefore, if the submitted code had direct
access to the assessment scripts, data leakage would be
trivial. Therefore, we need to uphold a strict separation between the
script performing the dynamic assessment and the running user submitted code in
order to preserve the integrity of our system.

\section{Submission lifecycle}
In this section we describe the life cycle phases which an assignment
goes through from submission to the assessment being returned to the
student. The life cycle of a specific assignment depends on several
factors. Particularly if we are dealing with an identified or
anonymous submission

An anonymous submission will only exist on the server while the
assessment is taking place.

An attributed submission, on the other hand, will persist on the
server for a certain amount of time. This, for instance, could allow
for repeated submissions to be differentially encoded providing
bandwidth savings.


In order to be able to track a submission through its lifecycle we
attach two attributes upon submission
\begin{description}
\item[UUID] Each received submission is assigned a Universally
  Unique ID (UUID). This UUID is used both internally and externally,
  i.e., it is returned to the user to be used as a handle for
  assessment retrieval
\item[metadata] A metadata object is assigned containing information
  about the submission such as which course and assignment it is
  submitted in response to.
\end{description}

%\section{Submission constituents}


\section{Executing untrusted code}
If the OnlienTA system is to fulfill its intended role, it is a
necessity that it executes arbitrary code submitted by
students.. For obvious reasons, we cannot trust
student submitted code not to perform inappropriate actions, may these
be unintended side-effects of programming errors or deliberate
malicious attempts to exploit the system.

\subsection{Sandboxing}
We will handle this challenge by executing the student-submitted code
in sandboxes where they have no chance of inducing side-effects on
other parts of the system, gaining access to privileged data or
affecting the assessment of other students assignments.

%Many variants of sandboxing technologies exists and ra

Sandboxing technologies range from fully-flgedged virtual machines to
rule-based execution environments for programs. We will here focus on
containers which is a type of OS-level virtualization and resource
confinement which  by enforcing separate
namespaces for e.g. networking, filesystems and system
permissions. The Linux kernel provide support or this kind of
sandboxing through the feature sets
\texttt{namespaces}\cite{namespaces}, cgroups, rlimit and seccomp.

There are several well-known "`packaged"' implementations OS-level
virtualization for Linux which is implemented using the namespaces
features. In this section we will describe a couple of these that has
been considered for use with OnlineTA.

\subsubsection{Docker}
Docker is a relatively recent addition to the family of application
containerization tools. Opposed to most other OS-level virtualization
technologies it focuses on application isolation rather
virtualization of an entire operating system. It has popularized a new
way of deploying and executing applications where, instead of
applications being installed on a shared system, applications are
deployed by starting a container which includes the application, its
dependencies and its configuration. \cite{whatisdocker}

Docker comes with a complete set of tools for building and managing
containers. These could be useful in supporting the TA's job of
developing and testing assessment units for assignments.

On the other hand, the codebase of Docker is very large and
contains a lot of features that are superfluous for our use
case. A large codebase also has a higher chance of containing security
critical bugs. The widespread adoption of docker for security critical
applications, however, mitigates this concern somewhat.

Privilege escalation vulerabilities has historically been more likely
to arise from peripheral feature sets (as seen in the recent QEmu
floppy driver vulnerability \cite{venom}), rather than the core containment
functionality itself.

%http://opensource.com/business/15/3/docker-security-future


\subsubsection{Sandstone}
As part of a related student project, a minimalist and modular
interface to the Linux container APIs were developed. The philosophy
behind this system, named
sandstone\footnote{\url{https://github.com/onlineta/sandstone}}, is to
provide access to the sandboxing features of Linux as small individual
building blocks which can be composed, providing the program executed
with the desired level of isolation.

The building blocks of Sandstone is implemented as small programs
written in the C language, each of which implements a part of the
Linux container system. The programs are composed through command
chaining. Exemplifiedied, the composition works as follows: Let $a$,
$b$, and $c$ be programs in Sandstone and let $p$ be the program that
we wish to execute in a sandboxed environment. We execute the process
with the command line \texttt{a b c p}. Then $b$ will be constrained
by the isolation provided by $a$, $c$ will be constrained by $a$ and
$b$ and $p$ will be constrained by $a$, $b$ and $c$ and will thus be
executed with the level of isolation that we desired. \cite{onlineta}

There are good reasons to be wary of custom built security
critical utilities. Security is hard to get right and custom built
utilities that never see widespread use will never go through the
public scrutiny offered to more publicly visible tools. A mitigating
feature of Sandstone in this regard is its relative simplicity and the
limited amount of code used in its implementation.

\subsubsection{Conclusions}
The containers each have their own individual strength and weaknesses
and both of them are able to serve the purpose for containing the
assessment process in OnlineTA. However, further practical testing is
needed draw firm conclusions about their suitability. Such testing is
enabled by the fact that our design, that we will later present,
features support for swapping containerization method.

%\section{Privileged operations}
%The system needs to perform several operations which cannot be
%performed by a regular user in Linux. In this section, we will li

\section{Design principles}
We have devised a number of principles that our system design will be
based on. These principles aims to simplify the design of our s

\paragraph{Modularity}
We want the components of our system to be modular and loosely
coupled. Large monolithic components tends to foster unmanageable
complexity which makes them harder to maintain and review for security
problems.
%As it will become clear from our following
%principles
Modularity also adds flexibility to our system by enabling certain
components to be swapped.

\paragraph{Clearly defined minimal interfaces}


\paragraph{Minimum permssions}
\label{sec:cap}

A common "`best practice"' related to the security aspects of software
development is to assign a minimalized set of permission to a
component required by the work that it needs to perform. Traditional
Unix environments only makes the distinction between a superuser
(root) and a regular user. It's common for applications to be started
with full superuser permissions and then, after performing privileged
actions,resume operations as a unprivileged user. It's important to
make sure that a process can never regain the privileges that it has
dropped.

%This helps
%mitigating the effects of exploitation of security 

The sharp separation between superusers and regular users no longer
exists in model versions of the Linux kernel following the
introduction of the \textit{Capabilities} interface \cite{cap7}. 

Capabilities allows individual processes running as regular users to
perform specified actions that would normally require super user
privileges.

\paragraph{Data ownership separation}
The most basic permission management primitive in Unix operating
systems is the concept of a user. We wish to enforce fine grained user
separation across the system such that a given user only have access
to what is absolutely necessary. A common concern of executing
applications inside a container is what happens in the unlikely event
that a process successfully manages to escape the container. In this
case, the attacker would usually end up having the same permissions as
the process executing the container. Therefore, we can mitigate the
consequences of a potential container escape by making sure that the
user executing container has access to as few things as possible in
the wider system.

%An important advantage of linux capabilities is that they follow a
%\textit{process} and not the user. This means that an attacker would
%need to exploit, either So even if an attacker manages to
%escape our container, he would 

\subsection{Securing special capabilities}
Despite our best efforts, we can never completely eliminate the
possibility that an adversary will be able to take advantage of the
capabilities given to our programs and force them to preform
unintended actions. For instance, gaining arbitrary code execution in
a process with the \texttt{chown} capability would allow one to change
\fxnote{That's also because our programs can't always reduce their privileges (they will need them for later on), so we need to make sure that we both give sufficient, but also not overly lavish capabilities.}
permissions of any file in the system. Since our security model to a
large extent relies on users having access to a minimalized set of
files, we would consider this to be a rather serious security
incident.

Secure Computing (seccomp) \cite{seccomp2} is a facility provided by
the Linux kernel to provide application sandboxing through the
filtering of syscalls. It allows an application to unidirectionally
transition into a secure state where all of its syscalls are filtered
by specified rules. Building on our example in the previous paragraph,
we can use the seccomp to filter the \texttt{chown} syscall such that
it only allows changing the owner of files to a UID within an allowed
range, e.g. $(\text{aaa000})_{36} - (\text(zzz999)_{36})$ and is only
allowed to change ownership of files within the submissions directory.

We can use seccomp to build an extra layer of security around our
programs which limits the consequences of an attacker gaining control
of our applications.

%\fxnote{discuss problem of go
%  spawning multiple threads per default somewhere}


\section{Handling user identities}
We will support assessing submissions from two groups of user:
anonymous and authenticated users. Submissions from these groups will
be handled in two different ways, both with regard to what services
are offered to the user, but also how we represent their submissions
internally. Submissions made by an authenticated user will be referred
to as an \textit{attributed} submission.

Anonymous submissions are removed after their life cycle has
concluded. Only the assessment of the submission persists until it has
been read by the submitting user.

%\fxnote{We should hold off describing our implementation of handling
%%  usernames through}

\subsubsection{Identified submissions}
For the time being, the scope of OnlineTA is limited to students at
DIKU. Thus, we can take advantage of the standardized usernames
assigned to everyone who is in some way associated with the University
of Copenhagen (KU-usernames), both students and
employees. KU-usernames are matched by the regular expression
\texttt{\^[a-z]\{3\}[0-9]\{3\}\$}, with the exception that vowels aren't used
as letters in generated usernames. We can use this
username generation scheme to our advantage since we can interpret the
KU-usernames as base 36 numbers and thus achieve a stateless and
bidirectional mapping between Linux UIDs and KU-usernames, e.g.:
\begin{equation*}
(\text{gfr534})_{36} = (993919360)_{10}
\end{equation*}

Since UIDs in Linux are represented as a 32-bit signed integer, actual
implementations of this scheme needs to take into account that the
(numerically) largest valid KU-username $(zzz999)_{36}$ is larger than
$(2^{31})_{10}$.

\paragraph{Verifying user identity}
Another ongoing student project is designing and implementing a
purpose-built GPG key server which are intended to be implemented into
the OnlineTA system. The purpose of this key server is to provide a
mapping between a KU-id and a GPG-key. Since all attributed
submissions are required to be signed with a GPG key we can verify the
identity of the submitting user by verifying the GPG signature of
their assignment.

At this stage, we have not found a suitable model for supporting group
submissions


\section{Interacting with the system}
In this section, we describe modes of interaction with the system for
making submissions and receiving assessments.

Since this system is intended to be used even by freshmen submitting
their first assignment, providing a simple, familiar, universal and
immediately accessible interface for submitting assignments is an
important goal. However, a secondary purpose of this system is, not
just aiding TAs in their grading work, but also to provide students
with continuous feedback while they are solving their
assignments. It's therefore important that we meet students where they
are and provide them with (from their perspective) the most seamless
interaction possible.

The first goal is best achieved through a well-designed web interface
for uploading assignments. The interface should, when
possible,
%\fxnote{Talk about when system overload causes long submission
%  times},
provide immediate feedback within the browser. As previously
mentioned, we have based our user identification on verifying that an
assignment has been signed with the GPG-key belonging to the user
claiming to have submitted the assignment. This poses a potential
obstacle when implementing attributed submissions through the web
interface. One option, is to require students to GPG sign their
assignments prior to submission.

%.. Talk about WAYF, browser ertificates, etc...

Many additional submission interfaces has been proposed since the
conception of OnlineTA. The prevailing proposal has been to implement
a command line interface which would allow a student to submit the
current folder or a file for assessment. The Windows equivalent of
this would be a Shell Extension adding tantamount functionality to the
right click menu of files and folders. We are not qualified to provide
equivalents for other platforms such as OSX, but in that particular
case, the command line interface would also be feasible. A tangential
advantage of this submission method is that it could be implemented to
only transmit deltas between repeated submissions and thus
significantly reduce upload time and internet bandwidth required for
submission.

Another submission interface under consideration is git. Since
revision control systems (primarily git) are already an integrated
part of the assignment implementation workflow of many students, we consider
eventual addition of git an important goal. Git integration would
allow submitting an assignment to OnlineTA for assessment simply by pushing the
appropriate remote repository. Furthermore, since git uses
differential encoding to update remote files, repeated submissions of
large assignments through git would save bandwidth compared to
repeated uploads of the entire submission.

%\fxnote{TODO: Argue why git is nice}



%Auditing system for similarities in assignments which can be used to
%flag suspected plagiarism


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% TeX-command-extra-options: "-enable-write18"
%%% End:
